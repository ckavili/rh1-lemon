---
apiVersion: gateway.networking.k8s.io/v1
kind: GatewayClass
metadata:
  name: openshift-ai-inference
spec:
  controllerName: openshift.io/gateway-controller/v1
---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  labels:
    istio.io/rev: openshift-gateway
  name: openshift-ai-inference
  namespace: openshift-ingress
spec:
  gatewayClassName: openshift-ai-inference
  listeners:
    - allowedRoutes:
        namespaces:
          from: All
      name: http
      port: 80
      protocol: HTTP
---
apiVersion: v1
kind: Namespace
metadata:
  name: lemonade-stand
---
apiVersion: serving.kserve.io/v1alpha1
kind: LLMInferenceService
metadata:
  annotations:
    opendatahub.io/model-type: generative
    openshift.io/display-name: llama-llm-d
    security.opendatahub.io/enable-auth: 'false'
  name: llama-llm-d
  namespace: lemonade-stand
  finalizers:
    - serving.kserve.io/llmisvc-finalizer
spec:
  model:
    name: llama32
    uri: oci://quay.io/redhat-ai-services/modelcar-catalog:llama-3.2-3b-instruct
  replicas: 48 # change replicas as needed
  router:
    gateway: {}
    route: {}
    scheduler:
      template:
        containers:
          - name: main
            resources:
              limits:
                cpu: '8'
                memory: 24Gi
              requests:
                cpu: '6'
                memory: 16Gi
  template:
    containers:
      - env:
          - name: VLLM_ADDITIONAL_ARGS
            value: '--model=/mnt/models --served-model-name=llama32 --disable-uvicorn-access-log --max-model-len=512 --gpu-memory-utilization=0.90 --max-num-batched-tokens=8192 --max-num-seqs=160 --enable-chunked-prefill'
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /health
            port: 8000
            scheme: HTTPS
          initialDelaySeconds: 120
          periodSeconds: 30
          timeoutSeconds: 30
        name: main
        resources:
          limits:
            cpu: '2'
            memory: 24Gi
            nvidia.com/gpu: '1'
          requests:
            cpu: '1'
            memory: 16Gi
            nvidia.com/gpu: '1'
    tolerations:
      - effect: NoSchedule
        key: nvidia.com/gpu
        value: NVIDIA-H200-PRIVATE

